{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents\n",
        "!pip install 'openai-agents[litellm]'\n",
        "# !pip install -Uq openai-agents \"openai-agents[litellm]\""
      ],
      "metadata": {
        "id": "cf8HTvAhsBsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "c33H1hH0iffV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "tTnmQPzPsNDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
        "from agents.extensions.models.litellm_model import LitellmModel\n",
        "# from google.colab import userdata\n",
        "\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "#       Company / LLM Model\n",
        "MODEL = \"gemini/gemini-2.0-flash\"\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GIDijSZBb1ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Main Function"
      ],
      "metadata": {
        "id": "iblsD2XOpGqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(model: str, api_key: str):\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in three lines.\",\n",
        "        model=LitellmModel(model=model, api_key=api_key),\n",
        "\n",
        "    )\n",
        "\n",
        "    result = Runner.run_sync(agent, \"What's AI Agent?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "main(model=MODEL, api_key=GEMINI_API_KEY)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wja_cJZgfp6A",
        "outputId": "d11821ae-4f41-4dee-d607-19171b97fd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Agents are intelligent systems.\n",
            "They perceive environments and take actions.\n",
            "Autonomously achieving specific goals.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Direct Method"
      ],
      "metadata": {
        "id": "6ucALcjXo9i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in three lines.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "\n",
        "    )\n",
        "\n",
        "result = Runner.run_sync(agent, \"What's AI Agent?\")\n",
        "print(result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrwCRb3loztN",
        "outputId": "3a37bf98-d549-4412-89e6-d1273a0bb961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An AI agent is a software entity.\n",
            "It perceives its environment and acts autonomously.\n",
            "To achieve specific goals in that environment.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Custom Function/Tool"
      ],
      "metadata": {
        "id": "8YqtCzTcrhB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also run this without main() function."
      ],
      "metadata": {
        "id": "kFbFfhUWsRNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def get_weather(city: str):\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "async def main(model: str, api_key: str):\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=LitellmModel(model=model, api_key=api_key),\n",
        "        tools=[get_weather],\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"What's the weather in Lahore?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "asyncio.run(main(model=MODEL, api_key=GEMINI_API_KEY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HGfGszBreb0",
        "outputId": "b969591d-e78c-4692-9dbb-40c84e06b314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I need the city.\n",
            "Please provide it, I'll check it,\n",
            "Then give weather back.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handsoff"
      ],
      "metadata": {
        "id": "9dg4CA0d91d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def get_weather(city: str):\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "weather_agent = Agent(\n",
        "        name=\"WeatherAssistant\",\n",
        "        instructions=\"You will share weather.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        tools=[get_weather],\n",
        "        handoff_description=\"Weather Assistant is expert in Weather Questions\"\n",
        "    )\n",
        "\n",
        "panacloud_agent = Agent(\n",
        "        name=\"PanacloudAssistant\",\n",
        "        instructions=\"You will answer Panacloud related queries.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        handoff_description=\"Panacloud Assistant is specialized for all Panacloud Queries. IT can search for Panacloud and provide answers.\"\n",
        "    )\n",
        "\n",
        "# Triage Agent = Boos / Crew Leader\n",
        "agent = Agent(\n",
        "        name=\"GeneralAssistant\",\n",
        "        instructions=\"You Chat with user for weather related queries and handoffs to WeatherAssistant or for Panacloud related queries handoffs to Panacloud Assistant.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        handoffs = [weather_agent, panacloud_agent],\n",
        "    )\n",
        "\n",
        "result = await Runner.run(agent, \"Hi\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFnEAfh7FS9o",
        "outputId": "3cb4d5ec-88bc-41cc-c13e-ab40a53b2178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0IioaVEDNIK",
        "outputId": "4182b9ad-4860-4780-f1a0-e3a45c93252f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_last_agent',\n",
              " 'context_wrapper',\n",
              " 'final_output',\n",
              " 'final_output_as',\n",
              " 'input',\n",
              " 'input_guardrail_results',\n",
              " 'last_agent',\n",
              " 'last_response_id',\n",
              " 'new_items',\n",
              " 'output_guardrail_results',\n",
              " 'raw_responses',\n",
              " 'to_input_list']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E0KcqVjpDS9W",
        "outputId": "9827cc05-669e-4c1d-9cf2-e416071f8edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GeneralAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"What's the weather in Lahore?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rMBiCKcCh7Y",
        "outputId": "75f7da9e-8f0c-41dd-f6a3-8631d87b1cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for Lahore\n",
            "The weather in Lahore is sunny.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hiNcCFTGDZ0s",
        "outputId": "eeb5b459-e0ad-4c0f-f7e6-a61a53309a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WeatherAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"What's Panacloud stands for?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLQdipluCr8v",
        "outputId": "c4b8243e-c1ff-4ea8-a531-a4bbf950e725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAIC stands for **Presidential Initiative for Artificial Intelligence & Computing**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JK81cgaiDauG",
        "outputId": "08e0ec28-4689-4e55-c78f-0227b868eaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PiaicAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"In Which country or city Panacloud located and whats the weather there?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nYoo-osGx0R",
        "outputId": "f137f7ab-b5ee-4369-84cc-b182aefa5726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAIC (Presidential Initiative for Artificial Intelligence and Computing) is located in **Pakistan**, primarily in the city of **Karachi**. However, it has initiatives and centers in other cities of Pakistan as well.\n",
            "\n",
            "Regarding the weather in Karachi: As of October 26, 2023, the weather in Karachi is generally sunny and warm. Temperatures can range from the mid-20s to the low 30s degrees Celsius (around 75-90 degrees Fahrenheit) during the day. The humidity is also typically moderate. Of course, weather can vary, so it's always a good idea to check a local weather forecast for the most up-to-date information.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.last_agent.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5e_YJz8CHCTh",
        "outputId": "404aad61-53b6-467f-b7dc-b26050df8698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PiaicAssistant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def get_weather(city: str):\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "weather_agent = Agent(\n",
        "        name=\"WeatherAssistant\",\n",
        "        instructions=\"You will share weather.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        tools=[get_weather],\n",
        "        handoff_description=\"Weather Assistant is expert in Weather Questions\"\n",
        "    )\n",
        "\n",
        "panacloud_agent = Agent(\n",
        "        name=\"PanacloudAssistant\",\n",
        "        instructions=\"You will answer Panacloud related queries & for weather related queries pass it to Weather Assistant\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        handoff_description=\"Panacloud Assistant is specialized for all Panacloud Queries. IT can search for Panacloud and provide answers.\",\n",
        "        handoffs=[weather_agent],\n",
        "    )\n",
        "\n",
        "# Triage Agent = Boos / Crew Leader\n",
        "agent = Agent(\n",
        "        name=\"GeneralAssistant\",\n",
        "        instructions=\"You Chat with user for weather related queries and handoffs to WeatherAssistant or for Panacloud related queries handoffs to Panacloud Assistant.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        handoffs = [weather_agent, panacloud_agent],\n",
        "    )\n",
        "\n",
        "result = await Runner.run(agent, \"Hi\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-iaDcAEHUGj",
        "outputId": "c1391281-f325-49e1-965c-ffbdea84d430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, how can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await Runner.run(agent, \"In Which country or city Panacloud located and whats the weather there?\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHqaPwEzHegA",
        "outputId": "52edadd0-b657-4f51-b300-f742b6614af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAIC is located in Pakistan, but I can't tell you the weather there. I'll transfer you to the Weather Assistant for that.\n",
            "\n",
            "PiaicAssistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def get_weather(city: str):\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "weather_agent = Agent(\n",
        "        name=\"WeatherAssistant\",\n",
        "        instructions=\"You will share weather.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        tools=[get_weather],\n",
        "        handoff_description=\"Weather Assistant is expert in Weather Questions\"\n",
        "    )\n",
        "\n",
        "panacloud_agent = Agent(\n",
        "        name=\"PanacloudAssistant\",\n",
        "        instructions=\"You will answer Panacloud related queries & for weather related queries pass it to Weather Assistant\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        handoff_description=\"Panacloud Assistant is specialized for all Panacloud Queries. IT can search for Panacloud and provide answers.\",\n",
        "        handoffs=[weather_agent],\n",
        "    )\n",
        "\n",
        "# Triage Agent = Boos / Crew Leader\n",
        "agent = Agent(\n",
        "        name=\"GeneralAssistant\",\n",
        "        instructions=\"You Chat with user for weather related queries and handoffs to WeatherAssistant or for Panacloud related queries handoffs to Panacloud Assistant.\",\n",
        "        model=LitellmModel(model=MODEL, api_key=GEMINI_API_KEY),\n",
        "        tools = [weather_agent.as_tool(tool_name=\"Weather_tool\", tool_description=\"You will share weather.\") ,\n",
        "                 panacloud_agent.as_tool(tool_name=\"Panacloud_tool\", tool_description=\"Panacloud Assistant is specialized for all Panacloud Queries. IT can search for Panacloud and provide answers.\")],\n",
        "    )\n",
        "\n",
        "result = await Runner.run(agent, \"What is Panacloud and what is weather in Lahore?\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loHqzKh_Jojk",
        "outputId": "eaad15e1-4e5a-4e22-a0a5-7c9241066d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for Lahore\n",
            "PIAIC is Pakistan Information and Technology Institute. The weather in Lahore is sunny. Do you have any other questions?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGar0llKE3FP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}